from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response, JSONResponse
import numpy as np
import cv2
import subprocess
import tempfile
import os
import uuid
import shutil
from fastapi import UploadFile, File, Form, Response
import os, uuid, tempfile, subprocess
import cv2, numpy as np


app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_methods=["*"],
    allow_headers=["*"],
    allow_credentials=True,
)

def resize_image(img, max_dim=800):
    h, w = img.shape[:2]
    if max(h, w) > max_dim:
        scale = max_dim / float(max(h, w))
        img = cv2.resize(img, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)
    return img

def generate_halftone(gray_img, block_size=6):
    h, w = gray_img.shape
    halftone = np.ones((h, w), dtype=np.uint8) * 255
    for y in range(0, h, block_size):
        for x in range(0, w, block_size):
            block = gray_img[y:y+block_size, x:x+block_size]
            avg = int(np.mean(block))
            radius = int((1 - avg / 255) * (block_size / 2))
            if radius > 0:
                cv2.circle(halftone,
                           (x + block_size // 2, y + block_size // 2),
                           radius,
                           0, -1)
    return halftone

@app.post("/analyze/")
async def analyze_image(file: UploadFile = File(...), edge_method: str = Form("canny")):
    content = await file.read()
    img_np = np.frombuffer(content, np.uint8)
    img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)

    if img is None:
        return JSONResponse(content={"error": "Nie uda≈Ço siƒô odczytaƒá obrazu."}, status_code=400)

    img = resize_image(img)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    if edge_method == "sobel":
        sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=3)
        edges = cv2.bitwise_or(sobelx, sobely)
    elif edge_method == "laplacian":
        edges = cv2.Laplacian(gray, cv2.CV_8U)
    elif edge_method == "adaptive":
        edges = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)
    elif edge_method == "dog":
        blur1 = cv2.GaussianBlur(gray, (5, 5), 1)
        blur2 = cv2.GaussianBlur(gray, (5, 5), 2)
        edges = cv2.absdiff(blur1, blur2)
        _, edges = cv2.threshold(edges, 15, 255, cv2.THRESH_BINARY)
    elif edge_method == "gaussian":
        edges = cv2.GaussianBlur(gray, (5, 5), 1)
        _, edges = cv2.threshold(edges, 127, 255, cv2.THRESH_BINARY)
    else:
        edges = cv2.Canny(gray, 50, 150)

    edge_count = int(np.sum(edges > 0))
    height, width = edges.shape
    density = edge_count / (height * width)
    k = int(np.interp(density, [0.01, 0.2], [2, 30]))
    return {"suggested_k": k, "density": density}

@app.post("/process/")
async def process_image(
    file: UploadFile = File(...),
    k: int = Form(5),
    brightness: float = Form(1.0),
    stroke_enabled: int = Form(1),
    use_halftone: int = Form(0),  # nowy
    edge_method: str = Form("canny"),
    
):
    content = await file.read()
    img_np = np.frombuffer(content, np.uint8)
    img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)

    if img is None:
        return JSONResponse(content={"error": "Nie uda≈Ço siƒô odczytaƒá obrazu."}, status_code=400)

    if k < 2 or k > 30:
        return JSONResponse(content={"error": "Nieprawid≈Çowa warto≈õƒá k. Dozwolone: 2‚Äì30."}, status_code=400)

    img = resize_image(img)
    color = cv2.bilateralFilter(img, 9, 75, 75)

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # wyb√≥r algorytmu
    if edge_method == "sobel":
        sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=3)
        edges = cv2.bitwise_or(sobelx, sobely)
    elif edge_method == "laplacian":
        edges = cv2.Laplacian(gray, cv2.CV_8U)
    elif edge_method == "adaptive":
        edges = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_MEAN_C,
            cv2.THRESH_BINARY_INV,
            11, 2
        )
    elif edge_method == "dog":
        blur1 = cv2.GaussianBlur(gray, (5, 5), 1)
        blur2 = cv2.GaussianBlur(gray, (5, 5), 2)
        edges = cv2.absdiff(blur1, blur2)
        _, edges = cv2.threshold(edges, 15, 255, cv2.THRESH_BINARY)
    elif edge_method == "gaussian":
        blurred = cv2.GaussianBlur(gray, (5, 5), 1)
        _, edges = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)
    else:  # domy≈õlnie Canny
        edges = cv2.Canny(gray, 50, 150)

    edges_inv = cv2.bitwise_not(edges)
    edges_rgb = cv2.cvtColor(edges_inv, cv2.COLOR_GRAY2BGR)

    data = np.float32(color).reshape((-1, 3))
    _, labels, centers = cv2.kmeans(
        data, k, None,
        (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2),
        10, cv2.KMEANS_RANDOM_CENTERS
    )
    quant = centers[labels.flatten()].reshape(img.shape).astype(np.uint8)

    hsv = cv2.cvtColor(quant, cv2.COLOR_BGR2HSV)
    poster_strength = max(1, int(1.0 / brightness * 5))
    hsv[..., 2] = (hsv[..., 2] // poster_strength) * poster_strength
    quant = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

    if use_halftone:
        # U≈ºywamy warto≈õci jasno≈õci (z HSV)
        hsv = cv2.cvtColor(quant, cv2.COLOR_BGR2HSV)
        v = hsv[..., 2]
        
        # Maskujemy tylko ciemne obszary (np. V < 60)
        shadow_mask = cv2.inRange(v, 0, 60)
        shadow_mask_3ch = cv2.cvtColor(shadow_mask, cv2.COLOR_GRAY2BGR)
        
        # Generujemy halftone (czarne kropki na bia≈Çym tle)
        gray_ht = cv2.cvtColor(quant, cv2.COLOR_BGR2GRAY)
        halftone = generate_halftone(gray_ht, block_size=6)
        halftone = cv2.cvtColor(halftone, cv2.COLOR_GRAY2BGR)

        # Odwr√≥ƒá halftone: bia≈Çe t≈Ço, czarne kropki ‚Üí czarne t≈Ço, bia≈Çe kropki
        halftone_inv = 255 - halftone

        # Na≈Ç√≥≈º halftone tylko tam, gdzie cie≈Ñ
        masked_halftone = cv2.bitwise_and(halftone_inv, shadow_mask_3ch)
        quant = cv2.subtract(quant, masked_halftone)

    toon = cv2.bitwise_and(quant, edges_rgb) if stroke_enabled else quant
    _, img_encoded = cv2.imencode('.png', toon)
    return Response(content=img_encoded.tobytes(), media_type="image/png")

@app.post("/preview/")
async def preview_image(file: UploadFile = File(...), edge_method: str = Form(...)):
    content = await file.read()
    img_np = np.frombuffer(content, np.uint8)
    img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)
    if img is None:
        return JSONResponse(content={"error": "Invalid image"}, status_code=400)

    img = resize_image(img)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    if edge_method == "sobel":
        sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=3)
        edges = cv2.bitwise_or(sobelx, sobely)
    elif edge_method == "laplacian":
        edges = cv2.Laplacian(gray, cv2.CV_8U)
    elif edge_method == "adaptive":
        edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)
    elif edge_method == "dog":
        blur1 = cv2.GaussianBlur(gray, (5, 5), 1)
        blur2 = cv2.GaussianBlur(gray, (5, 5), 2)
        edges = cv2.absdiff(blur1, blur2)
        edges = cv2.normalize(edges, None, 0, 255, cv2.NORM_MINMAX)
        edges = np.uint8(edges)
    elif edge_method == "gaussian":
        edges = cv2.GaussianBlur(gray, (5, 5), 1)
        _, edges = cv2.threshold(edges, 127, 255, cv2.THRESH_BINARY)
    else:
        edges = cv2.Canny(gray, 100, 200)

    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
    _, img_encoded = cv2.imencode('.png', edges_rgb)
    return Response(content=img_encoded.tobytes(), media_type="image/png")

@app.post("/best-edge/")
async def best_edge_method(file: UploadFile = File(...)):
    content = await file.read()
    img_np = np.frombuffer(content, np.uint8)
    img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)

    if img is None:
        return JSONResponse(content={"error": "Nie uda≈Ço siƒô odczytaƒá obrazu."}, status_code=400)

    img = resize_image(img)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    methods = {
        "canny": lambda: cv2.Canny(gray, 50, 150),
        "sobel": lambda: cv2.bitwise_or(
            cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3),
            cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=3)
        ),
        "laplacian": lambda: cv2.Laplacian(gray, cv2.CV_8U),
        "adaptive": lambda: cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2),
        "dog": lambda: cv2.threshold(
            cv2.absdiff(cv2.GaussianBlur(gray, (5, 5), 1), cv2.GaussianBlur(gray, (5, 5), 2)),
            15, 255, cv2.THRESH_BINARY)[1],
        "gaussian": lambda: cv2.threshold(
            cv2.GaussianBlur(gray, (5, 5), 1), 127, 255, cv2.THRESH_BINARY)[1]
    }

    results = []
    for method, func in methods.items():
        edges = func()
        density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
        results.append((method, density))

    # wybierz metodƒô o ‚Äû≈õredniej‚Äù gƒôsto≈õci, czyli zbli≈ºonƒÖ do idealnej np. 0.05‚Äì0.15
    ideal_density = 0.10
    best = min(results, key=lambda x: abs(x[1] - ideal_density))

    return {"best_method": best[0], "density": round(best[1], 4)}


@app.post("/process-video/")
async def process_video(
    file: UploadFile = File(...),
    k: int = Form(5),
    brightness: float = Form(1.0),
    stroke_enabled: int = Form(1),
    use_halftone: int = Form(0),
    edge_method: str = Form("canny")
):
    temp_dir = tempfile.gettempdir()
    temp_input_path = os.path.join(temp_dir, f"{uuid.uuid4()}.mp4")
    temp_output_raw = os.path.join(temp_dir, f"{uuid.uuid4()}_raw.mp4")
    temp_output_final = os.path.join(temp_dir, f"{uuid.uuid4()}_final.mp4")

    with open(temp_input_path, "wb") as f:
        f.write(await file.read())

    cap = cv2.VideoCapture(temp_input_path)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # surowe wyj≈õcie
    fps = cap.get(cv2.CAP_PROP_FPS)
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    out = cv2.VideoWriter(temp_output_raw, fourcc, fps, (w, h))

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Krawƒôdzie
        if edge_method == "sobel":
            sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3)
            sobely = cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=3)
            edges = cv2.bitwise_or(sobelx, sobely)
        elif edge_method == "laplacian":
            edges = cv2.Laplacian(gray, cv2.CV_8U)
        elif edge_method == "adaptive":
            edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)
        elif edge_method == "dog":
            blur1 = cv2.GaussianBlur(gray, (5, 5), 1)
            blur2 = cv2.GaussianBlur(gray, (5, 5), 2)
            edges = cv2.absdiff(blur1, blur2)
            _, edges = cv2.threshold(edges, 15, 255, cv2.THRESH_BINARY)
        elif edge_method == "gaussian":
            blurred = cv2.GaussianBlur(gray, (5, 5), 1)
            _, edges = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)
        else:
            edges = cv2.Canny(gray, 50, 150)

        edges_inv = cv2.bitwise_not(edges)
        edges_rgb = cv2.cvtColor(edges_inv, cv2.COLOR_GRAY2BGR)

        # Koloryzacja i poster
        color = cv2.bilateralFilter(frame, 9, 75, 75)
        data = np.float32(color).reshape((-1, 3))
        _, labels, centers = cv2.kmeans(
            data, k, None,
            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2),
            10, cv2.KMEANS_RANDOM_CENTERS
        )
        quant = centers[labels.flatten()].reshape(frame.shape).astype(np.uint8)

        hsv = cv2.cvtColor(quant, cv2.COLOR_BGR2HSV)
        poster_strength = max(1, int(1.0 / brightness * 5))
        hsv[..., 2] = (hsv[..., 2] // poster_strength) * poster_strength
        quant = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

        # Halftone
        if use_halftone:
            hsv = cv2.cvtColor(quant, cv2.COLOR_BGR2HSV)
            v = hsv[..., 2]
            shadow_mask = cv2.inRange(v, 0, 60)
            shadow_mask_3ch = cv2.cvtColor(shadow_mask, cv2.COLOR_GRAY2BGR)
            gray_ht = cv2.cvtColor(quant, cv2.COLOR_BGR2GRAY)
            halftone = generate_halftone(gray_ht, block_size=6)
            halftone = cv2.cvtColor(halftone, cv2.COLOR_GRAY2BGR)
            halftone_inv = 255 - halftone
            masked_halftone = cv2.bitwise_and(halftone_inv, shadow_mask_3ch)
            quant = cv2.subtract(quant, masked_halftone)

        final = cv2.bitwise_and(quant, edges_rgb) if stroke_enabled else quant
        out.write(final)

    cap.release()
    out.release()

    # üîÅ RE-ENCODUJ do H.264 (libx264)
    subprocess.run([
        "ffmpeg", "-y",
        "-i", temp_output_raw,
        "-c:v", "libx264",
        "-preset", "ultrafast",
        "-pix_fmt", "yuv420p",
        temp_output_final
    ], check=True)

    with open(temp_output_final, "rb") as f:
        video_bytes = f.read()

    os.remove(temp_input_path)
    os.remove(temp_output_raw)
    os.remove(temp_output_final)

    return Response(content=video_bytes, media_type="video/mp4")